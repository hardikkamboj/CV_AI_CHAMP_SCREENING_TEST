{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we will use the data that we got from task 2 and convert it to more clean data by removing stop words, lemmanitizing and removing numbers and special characters\n",
    "## Running this notebook, we will get a clean_data.csv file, which will contain clean data with 50 rows representing for each of the 50 user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resume   Contactchristian.szegedy@gmail.comwww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resume   Contactanshumanpandey001@gmail.comwww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resume   Contact7989921656 (Mobile)dineshparsa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resume   Contact7827876767 (Mobile)aditya.jais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resume   Contactsonisinha.25022000@gmail.comww...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Resume   Contactchristian.szegedy@gmail.comwww...\n",
       "1  Resume   Contactanshumanpandey001@gmail.comwww...\n",
       "2  Resume   Contact7989921656 (Mobile)dineshparsa...\n",
       "3  Resume   Contact7827876767 (Mobile)aditya.jais...\n",
       "4  Resume   Contactsonisinha.25022000@gmail.comww..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Lenovo\\CV_AI_CHAMP_SCREENING_TEST\\Task_2\\data.csv',index_col = 0)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2562.12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number and punc removal\n",
    "def letters_only(astr):\n",
    "    \"\"\"\n",
    "    input - string (word)\n",
    "    output - True if the word contains only alphabets\n",
    "             else False\n",
    "    \"\"\"\n",
    "    return astr.isalpha()\n",
    "\n",
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#stop words \n",
    "stop_words = set(stopwords.words('english')) \n",
    "stop_words.add('resume') #because it appears in every file, so its unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_doc(docs):\n",
    "    \"\"\"\n",
    "    arguement - \n",
    "       docs - collecetion (list) of documents containing text\n",
    "       \n",
    "    return - \n",
    "       cleaned_doc - lemmanatizing, removing symbols,punctuations, numbers, and stop words from the input.\n",
    "                     it also converts each word to lower case.\n",
    "    \"\"\"\n",
    "    cleaned_doc = []\n",
    "    for doc in docs:\n",
    "        cleaned_doc.append(\" \".join((lemmatizer.lemmatize(word)).lower()\n",
    "                          for word in doc.split()\n",
    "                          if letters_only(word) and \n",
    "                                   not word.lower() in stop_words))\n",
    "    return cleaned_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = clean_doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that length = 50\n",
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resume\\xa0 \\xa0Contactchristian.szegedy@gmail.comwww.linkedin.com/in/christian-szegedy-bb284816 (LinkedIn)Top SkillsMachine LearningAlgorithmsArtificial IntelligenceLanguagesHungarianEnglishGermanChristian SzegedyStaff Research Scientist at GoogleSan Francisco Bay AreaSummaryTrying to solve math.ExperienceGoogle9 years 9 monthsStaff Research ScientistOctober 2015\\xa0-\\xa0Present\\xa0(4 years 11 months)Deep Learning, Artificial Intelligence, Computer Vision, Video Analysis, FormalReasoning.Senior Research ScientistFebruary 2015\\xa0-\\xa0October 2015\\xa0(9 months)Computer Vision, Video Analysis, Artificial IntelligenceSoftware engineerDecember 2010\\xa0-\\xa0February 2015\\xa0(4 years 3 months)Computer vision, machine learning, advertisement pricing optimization.Cadence Design SystemsResearch Scientist2005\\xa0-\\xa02010\\xa0(5 years)VLSI CAD physical design, logic synthesisUniversity of BonnResearch Assistant1998\\xa0-\\xa02005\\xa0(7 years)Discrete Mathematics, mathematical optimization, VLSI CAD physical design,logic synthesisEducationRheinische Friedrich-Wilhelms-Universität Bonn / University of Bonn\\xa0 Page 1 of 2mailto:christian.szegedy@gmail.comhttps://www.linkedin.com/in/christian-szegedy-bb284816?jobid=1234&lipi=urn%3Ali%3Apage%3Ad_jobs_easyapply_pdfgenresume%3B9tdIznTCQMKFHsxgim8MiQ%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_jobs_easyapply_pdfgenresume-v02_profilehttps://www.linkedin.com/in/christian-szegedy-bb284816?jobid=1234&lipi=urn%3Ali%3Apage%3Ad_jobs_easyapply_pdfgenresume%3B9tdIznTCQMKFHsxgim8MiQ%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_jobs_easyapply_pdfgenresume-v02_profile\\xa0 \\xa0Doctor of Philosophy (Ph.D.),\\xa0Applied Mathematics\\xa0·\\xa0(1998\\xa0-\\xa02005)Rheinische Friedrich-Wilhelms-Universität Bonn / University of BonnMaster’s Degree,\\xa0Mathematics\\xa0·\\xa0(1994\\xa0-\\xa01998)Eötvös Loránd TudományegyetemMathematics and Computer Science\\xa0·\\xa0(1990\\xa0-\\xa01992)Fazekas Mihaly Fov Gyak Gimn.High School\\xa0\\xa0·\\xa0(1986\\xa0-\\xa01990)\\xa0 Page 2 of 2'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skillsmachine learningalgorithmsartificial intelligencelanguageshungarianenglishgermanchristian szegedystaff research scientist googlesan francisco bay areasummarytrying solve year monthsstaff research scientistoctober present year artificial computer video research scientistfebruary october video artificial intelligencesoftware engineerdecember february year machine advertisement pricing design systemsresearch cad physical logic synthesisuniversity bonnresearch mathematical vlsi cad physical synthesiseducationrheinische bonn university bonn page doctor philosophy applied mathematics bonn university mathematics loránd tudományegyetemmathematics computer science mihaly fov gyak school page'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look how is the above code after cleaning\n",
    "clean_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting it into dataframe and getting the csv file. \n",
    "clean_data = pd.DataFrame(clean_text,columns = ['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finally, getting the csv file \n",
    "clean_data.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
